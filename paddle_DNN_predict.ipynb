{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.dygraph as dygraph\n",
    "from paddle.fluid.dygraph import Linear\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续特征保留特征\n",
    "test_col = [ 'recency', 'frequency', 'monetary', 'avg_discount', 'items_total',\n",
    "            'goods_price_last', 'goods_price_max', 'goods_price_min', 'goods_price_avg', 'goods_price_std', \n",
    "            'payment_max', 'payment_min', 'payment_avg', 'payment_std','gender', \n",
    "            'order_pay_time_diff_end-to-last2', 'order_double11_sum', \n",
    "            'rs', 'fs', 'ms', 'RFM', 'rfms', 'order_interval',]\n",
    "train_col = test_col + ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为非归一化的train test 特征，无customer id和z-score后的rfm\n",
    "d = pd.read_csv('train_features2.csv')\n",
    "d = d[train_col]\n",
    "# d.to_csv('train2.csv',index=False)\n",
    "\n",
    "d = pd.read_csv('test_features2.csv')\n",
    "d = d[test_col]\n",
    "# d.to_csv('test2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "columns = d.columns\n",
    "for col in columns:\n",
    "    max_num = d[col].max()\n",
    "    min_num = d[col].min()\n",
    "    avg = d[col].mean()\n",
    "    d[col] = (d[col] - avg)/(max_num - min_num)\n",
    "d.to_csv('train_1.csv',header=None,index=False)\n",
    "\n",
    "columns = d.columns\n",
    "for col in columns:\n",
    "    max_num = d[col].max()\n",
    "    min_num = d[col].min()\n",
    "    avg = d[col].mean()\n",
    "    d[col] = (d[col] - avg)/(max_num - min_num)\n",
    "d.to_csv('test_1.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有归一化方法的 load_data，用该方法时，需要载入 train.csv 和 test.csv\n",
    "def load_data(path,istrain):\n",
    "    # 从文件导入数据\n",
    "    datafile = path\n",
    "    # data = np.fromfile(datafile)\n",
    "    data = pd.read_csv(datafile)\n",
    "    \n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\n",
    "    feature_names = data.columns\n",
    "    feature_num = len(feature_names)\n",
    "    data = np.array(data)\n",
    "\n",
    "    \n",
    "\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\n",
    "    data = data.reshape([-1, feature_num])\n",
    "    \n",
    "    # 训练集和测试集的划分比例\n",
    "    #ratio = 0.8\n",
    "\n",
    "    # 将原数据集拆分成训练集和测试集\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\n",
    "    # 测试集和训练集必须是没有交集的\n",
    "    if istrain == True:\n",
    "        ratio = 0.8\n",
    "        offset = int(data.shape[0] * ratio)\n",
    "        training_data = data[:offset]\n",
    "        test_data = data[offset:]\n",
    "    else:\n",
    "        training_data = data\n",
    "        test_data = None\n",
    "\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载处理后的数据\n",
    "training_data, test_data = load_data('train_1.csv',True)\n",
    "print('train set done.')\n",
    "\n",
    "pre_data, none = load_data('test_1.csv',False)\n",
    "print('test set done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建多层神经网络\n",
    "class Regressor(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(Regressor, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        # 定义三层全连接层，输出维度是1，激活函数为tanh\n",
    "        self.fc1 = Linear(input_dim=23, output_dim=128, act='relu') # 输入层，input dim 为数据维度大小\n",
    "        # self.fc2 = Linear(input_dim=128, output_dim=128, act='tanh')\n",
    "        self.fc2 = Linear(input_dim=128, output_dim=1, act='sigmoid')\n",
    "        # self.fc3 = Linear(input_dim=128, output_dim=1, act='sigmoid') # 输出二维softmax后的概率，分别代表01 label的概率\n",
    "    # 网络的前向计算函数\n",
    "    def forward(self, inputs):\n",
    "        fc1 = self.fc1(inputs)\n",
    "        # fc2 = self.fc2(fc1)\n",
    "        # x = self.fc3(fc2)\n",
    "        x = self.fc2(fc1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    # 声明定义好的线性回归模型\n",
    "    model = Regressor(\"Regressor\")\n",
    "    # 开启模型训练模式\n",
    "    model.train()\n",
    "    # 定义优化算法，这里使用随机梯度下降-SGD\n",
    "    # 学习率设置为0.01\n",
    "    opt = fluid.optimizer.Adam(learning_rate=0.00001, parameter_list=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义带权交叉熵\n",
    "def wce_loss(pred, label, w=80, epsilon=1e-05): # w 是给到 y=1 类别的权重，越大越重视\n",
    "    label = fluid.layers.clip(label, epsilon, 1-epsilon)\n",
    "    pred = fluid.layers.clip(pred, epsilon, 1-epsilon)\n",
    "\n",
    "    loss = -1 * (w * label * fluid.layers.log(pred) + (1 - label) * fluid.layers.log(1 - pred))\n",
    "    loss = fluid.layers.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练和保存\n",
    "with dygraph.guard(fluid.CPUPlace()):\n",
    "    EPOCH_NUM = 30   # 设置外层循环次数\n",
    "    BATCH_SIZE = 4096  # 设置batch大小\n",
    "    \n",
    "    # 定义外层循环\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\n",
    "        np.random.shuffle(training_data)\n",
    "        # 将训练数据进行拆分，每个batch包含10条数据\n",
    "        mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\n",
    "        \n",
    "        # 定义内层循环\n",
    "        for iter_id, mini_batch in enumerate(mini_batches):\n",
    "            x = np.array(mini_batch[:, :-1]).astype('float32') # 获得当前批次训练数据\n",
    "            y = np.array(mini_batch[:, -1:]).astype('float32') # 获得当前批次训练标签（真实房价）\n",
    "\n",
    "            # 将numpy数据转为飞桨动态图variable形式\n",
    "            buyer_features = dygraph.to_variable(x)\n",
    "            result = dygraph.to_variable(y)\n",
    "            \n",
    "            # 前向计算\n",
    "            predicts = model(buyer_features)\n",
    "            # loss = fluid.layers.log_loss(predicts, prices)\n",
    "            loss = wce_loss(predicts, result)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            # logloss = fluid.layers.log_loss(predicts, prices)\n",
    "\n",
    "            if iter_id % 20 == 0:\n",
    "                print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()),)\n",
    "     \n",
    "            # 反向传播\n",
    "            avg_loss.backward()\n",
    "            # 最小化loss,更新参数\n",
    "            opt.minimize(avg_loss)\n",
    "            # 清除梯度\n",
    "            model.clear_gradients()\n",
    "    # 保存模型\n",
    "    fluid.save_dygraph(model.state_dict(), 'DNN_model')\n",
    "    print(\"模型保存成功，模型参数保存在DNN_model中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dygraph.guard():\n",
    "    # 参数为保存模型参数的文件地址\n",
    "    model_dict, _ = fluid.load_dygraph('DNN_model')\n",
    "    model.load_dict(model_dict)\n",
    "    model.eval()\n",
    "    # x = np.array(mini_batch[:, :-1]).astype('float32') # 获得当前批次训练数据\n",
    "    pre_data, _ = load_data('test_1.csv', istrain=False)\n",
    "    pre = pre_data.astype('float32')\n",
    "\n",
    "    pre = dygraph.to_variable(pre)\n",
    "    results = model(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('test_1.csv')\n",
    "results = results.numpy()\n",
    "temp = pd.DataFrame(columns=['customer_id','result'])\n",
    "temp['customer_id'] = a['customer_id']\n",
    "temp['result'] = results\n",
    "temp.reset_index(drop=True).sort_values('customer_id', ascending=True, inplace=True,)\n",
    "temp.to_csv('submission_DNN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
